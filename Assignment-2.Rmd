---
title: "Assignment-2"
author: "Pete Cuppernull"
date: "1/27/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Load Packages
```{r}
library(tidyverse)
library(broom) 
library(rsample) 
library(patchwork)
library(corrplot)
library(ISLR)
library(caret)
library(class)
```

# 1. The Bayes Classifier

###Parts A-C - create data
```{r}
##Set Seed
set.seed(1414)

##Create Dataset
#Create x1 and x2
x1 <- runif(200, -1, 1)
x2 <- runif(200, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

head(data)

##Calculate Y = ...
#Create error column
error <- rnorm(200, 0, 0.25)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x1^2 + x2 + x2^2 + error)

ggplot(data, aes(Y)) +
  geom_histogram()
```

###d. 
```{r}

#Convert Ys to log-odds
probability_function <- function(model){
  odds <- exp(model)
  probability <- odds / (1 + odds)
  return(probability)
}

data_success <- data %>%
  mutate(prob_success = probability_function(Y)) %>%
  mutate(Success = as.factor(if_else(prob_success > 0.5, "Yes", "No")))

###Create grid
bg_1 <- as.data.frame(rep(seq(-1, 1, 0.05), 41))
bg_2 <- as.data.frame(rep(seq(-1, 1, 0.05), each = 41))

bg_grid <- cbind(bg_1, bg_2)
colnames(bg_grid) <- c("X1", "X2")
bg_grid <- bg_grid %>%
  mutate(Y = X1 + X1^2 + X2 + X2^2) %>%
  mutate(prob_success = probability_function(Y)) %>%
  mutate(Success = as.factor(if_else(prob_success > 0.5, "Yes", "No")))
  

ggplot() +
  geom_point(data = data_success, mapping = aes(x1, x2, color = Success)) +
  geom_point(data = bg_grid, mapping = aes(X1, X2, color = Success), alpha = .15) +
  labs(x = "X1",
       y = "X2",
       title = "Successes of Simulated Data")
```

JUST NEED TO OVERLAY DECISION BOUNDARY

2. Differences between LDA and QDA
A. 
```{r}
#Create x1 and x2

create_data <- function(){
x1 <- runif(1000, -1, 1)
x2 <- runif(1000, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

#Create error column
error <- rnorm(1000, 0, 1)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data1 <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x2 + error) %>%
  mutate(class = if_else(Y>=0, 1, 0))

data1
}

run_models <- function(iteration_number){
  iteration <- iteration_number
  ##create partitions
split <- initial_split(create_data(), prop = .7) 
train <- training(split)
test <- testing(split)

##run LDA and save error rates
lda_m1 <- MASS::lda(class ~ x1 + x2, data = train)

pred_lda_test <- predict(lda_m1, 
                newdata = test)
pred_lda_train <- predict(lda_m1, 
                newdata = train)


table_lda_test <- table(test$class,pred_lda_test$class)
table_lda_train <- table(train$class,pred_lda_train$class)

error_lda_test <- sum(table_lda_test[row(table_lda_test) != col(table_lda_test)]) / sum(table_lda_test)
error_lda_train <- sum(table_lda_train[row(table_lda_train) != col(table_lda_train)]) / sum(table_lda_train)

##run DDA and save error rates
qda_m1 <- MASS::qda(class ~ x1 + x2, data = train)

pred_qda_test <- predict(qda_m1, 
                newdata = test)
pred_qda_train <- predict(qda_m1, 
                newdata = train)

table_qda_test <- table(test$class,pred_qda_test$class)
table_qda_train <- table(train$class,pred_qda_train$class)

error_qda_test <- sum(table_qda_test[row(table_qda_test) != col(table_qda_test)]) / sum(table_qda_test)
error_qda_train <- sum(table_qda_train[row(table_qda_train) != col(table_qda_train)]) / sum(table_qda_train)

#Collect results
results <- as.data.frame(rbind(c(iteration, error_lda_train, error_lda_test, error_qda_train, error_qda_test)))

colnames(results) <- c("iteration", "LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")
results
}

##Run 1000 sims
final_results_NL <- map_dfr(1:1000, run_models)

final_results_NL <- final_results_NL %>%
  select(-iteration)

```

##2b - Summarize Results
### Tabular
```{r}
skimr::skim(final_results_NL)
```

###Graphical - build this out more
```{r}
ggplot(final_results_NL) +
  geom_density(aes(`LDA Training Error`, color = "LDA Training Error"), alpha = .25) +
  geom_vline(aes(xintercept = mean(`LDA Training Error`), color = "LDA Training Error"), size = 1.2) +
  geom_density(aes(`LDA Test Error`, color = "LDA Test Error"), alpha = .25) +
  geom_vline(aes(xintercept = mean(`LDA Test Error`), color = "LDA Test Error"), size = 1.2) +
  geom_density(aes(`QDA Training Error`, color = "QDA Training Error"), alpha = .25) +
  geom_vline(aes(xintercept = mean(`QDA Training Error`), color = "QDA Training Error"), size = 1.2) +
  geom_density(aes(`QDA Test Error`, color = "QDA Test Error"), alpha = .25) +
  geom_vline(aes(xintercept = mean(`QDA Test Error`), color = "QDA Test Error"), size = 1.2) +
  scale_color_brewer(type = "div",
                     name = NULL,
                     breaks = c("LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")) +
  labs(title = "Distribution of LDA and QDA training and test Error Rates",
       subtitle = "Mean denoted by vertical line",
       x = "Error Rate",
       y = "Frequency",
       legend = "Model")
```



##3
```{r}
create_data_NL <- function(){
x1 <- runif(1000, -1, 1)
x2 <- runif(1000, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

#Create error column
error <- rnorm(1000, 0, 1)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data1 <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x1^2 + x2 + x2^2 + error) %>%
  mutate(class = if_else(Y>=0, 1, 0))

data1
}

run_models_NL <- function(iteration_number){
  iteration <- iteration_number
  ##create partitions
split <- initial_split(create_data_NL(), prop = .7) 
train <- training(split)
test <- testing(split)

##run LDA and save error rates
lda_m1 <- MASS::lda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_lda_test <- predict(lda_m1, 
                newdata = test)
pred_lda_train <- predict(lda_m1, 
                newdata = train)


table_lda_test <- table(test$class,pred_lda_test$class)
table_lda_train <- table(train$class,pred_lda_train$class)

error_lda_test <- sum(table_lda_test[row(table_lda_test) != col(table_lda_test)]) / sum(table_lda_test)
error_lda_train <- sum(table_lda_train[row(table_lda_train) != col(table_lda_train)]) / sum(table_lda_train)

##run DDA and save error rates
qda_m1 <- MASS::qda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_qda_test <- predict(qda_m1, 
                newdata = test)
pred_qda_train <- predict(qda_m1, 
                newdata = train)

table_qda_test <- table(test$class,pred_qda_test$class)
table_qda_train <- table(train$class,pred_qda_train$class)

error_qda_test <- sum(table_qda_test[row(table_qda_test) != col(table_qda_test)]) / sum(table_qda_test)
error_qda_train <- sum(table_qda_train[row(table_qda_train) != col(table_qda_train)]) / sum(table_qda_train)

#Collect results
results <- as.data.frame(rbind(c(iteration, error_lda_train, error_lda_test, error_qda_train, error_qda_test)))

colnames(results) <- c("iteration", "LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")
results
}

final_results_NL <- map_dfr(1:1000, run_models_NL)

final_results_NL <- final_results_NL %>%
  select(-iteration)
```

###3b
```{r}
skimr::skim(final_results_NL)
```

##4
```{r, eval=FALSE}
create_data_NL_100 <- function(){
x1 <- runif(100, -1, 1)
x2 <- runif(100, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

#Create error column
error <- rnorm(100, 0, 1)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data1 <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x1^2 + x2 + x2^2 + error) %>%
  mutate(class = if_else(Y>=0, 1, 0))

data1
}

create_data_NL_10000 <- function(){
x1 <- runif(10000, -1, 1)
x2 <- runif(10000, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

#Create error column
error <- rnorm(10000, 0, 1)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data1 <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x1^2 + x2 + x2^2 + error) %>%
  mutate(class = if_else(Y>=0, 1, 0))

data1
}

create_data_NL_100000 <- function(){
x1 <- runif(100000, -1, 1)
x2 <- runif(100000, -1, 1)

#Turn into DFs
data <- as.data.frame(x1) 
x2 <- as.data.frame(x2) 

#Create ID columns
data$obs <- seq.int(nrow(data))
x2$obs <- seq.int(nrow(x2))

#Join columns
data <- data %>%
  left_join(x2) %>%
  select(obs, x1, x2)

#Create error column
error <- rnorm(100000, 0, 1)
error <- as.data.frame(error)
error$obs <- seq.int(nrow(error))

#Join error and calculate Y
data1 <- data %>%
  left_join(error) %>%
  mutate(Y = x1 + x1^2 + x2 + x2^2 + error) %>%
  mutate(class = if_else(Y>=0, 1, 0))

data1
}

run_models_NL_100 <- function(iteration_number){
  iteration <- iteration_number
  ##create partitions
split <- initial_split(create_data_NL_100(), prop = .7) 
train <- training(split)
test <- testing(split)

##run LDA and save error rates
lda_m1 <- MASS::lda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_lda_test <- predict(lda_m1, 
                newdata = test)
pred_lda_train <- predict(lda_m1, 
                newdata = train)


table_lda_test <- table(test$class,pred_lda_test$class)
table_lda_train <- table(train$class,pred_lda_train$class)

error_lda_test <- sum(table_lda_test[row(table_lda_test) != col(table_lda_test)]) / sum(table_lda_test)
error_lda_train <- sum(table_lda_train[row(table_lda_train) != col(table_lda_train)]) / sum(table_lda_train)

##run DDA and save error rates
qda_m1 <- MASS::qda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_qda_test <- predict(qda_m1, 
                newdata = test)
pred_qda_train <- predict(qda_m1, 
                newdata = train)

table_qda_test <- table(test$class,pred_qda_test$class)
table_qda_train <- table(train$class,pred_qda_train$class)

error_qda_test <- sum(table_qda_test[row(table_qda_test) != col(table_qda_test)]) / sum(table_qda_test)
error_qda_train <- sum(table_qda_train[row(table_qda_train) != col(table_qda_train)]) / sum(table_qda_train)

#Collect results
results <- as.data.frame(rbind(c(iteration, error_lda_train, error_lda_test, error_qda_train, error_qda_test)))

colnames(results) <- c("iteration", "LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")
results
}

run_models_NL_10000 <- function(iteration_number){
  iteration <- iteration_number
  ##create partitions
split <- initial_split(create_data_NL_10000(), prop = .7) 
train <- training(split)
test <- testing(split)

##run LDA and save error rates
lda_m1 <- MASS::lda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_lda_test <- predict(lda_m1, 
                newdata = test)
pred_lda_train <- predict(lda_m1, 
                newdata = train)


table_lda_test <- table(test$class,pred_lda_test$class)
table_lda_train <- table(train$class,pred_lda_train$class)

error_lda_test <- sum(table_lda_test[row(table_lda_test) != col(table_lda_test)]) / sum(table_lda_test)
error_lda_train <- sum(table_lda_train[row(table_lda_train) != col(table_lda_train)]) / sum(table_lda_train)

##run DDA and save error rates
qda_m1 <- MASS::qda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_qda_test <- predict(qda_m1, 
                newdata = test)
pred_qda_train <- predict(qda_m1, 
                newdata = train)

table_qda_test <- table(test$class,pred_qda_test$class)
table_qda_train <- table(train$class,pred_qda_train$class)

error_qda_test <- sum(table_qda_test[row(table_qda_test) != col(table_qda_test)]) / sum(table_qda_test)
error_qda_train <- sum(table_qda_train[row(table_qda_train) != col(table_qda_train)]) / sum(table_qda_train)

#Collect results
results <- as.data.frame(rbind(c(iteration, error_lda_train, error_lda_test, error_qda_train, error_qda_test)))

colnames(results) <- c("iteration", "LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")
results
}

run_models_NL_100000 <- function(iteration_number){
  iteration <- iteration_number
  ##create partitions
split <- initial_split(create_data_NL_100000(), prop = .7) 
train <- training(split)
test <- testing(split)

##run LDA and save error rates
lda_m1 <- MASS::lda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_lda_test <- predict(lda_m1, 
                newdata = test)
pred_lda_train <- predict(lda_m1, 
                newdata = train)


table_lda_test <- table(test$class,pred_lda_test$class)
table_lda_train <- table(train$class,pred_lda_train$class)

error_lda_test <- sum(table_lda_test[row(table_lda_test) != col(table_lda_test)]) / sum(table_lda_test)
error_lda_train <- sum(table_lda_train[row(table_lda_train) != col(table_lda_train)]) / sum(table_lda_train)

##run QDA and save error rates
qda_m1 <- MASS::qda(class ~ x1 + x1^2 + x2 + x2^2, data = train)

pred_qda_test <- predict(qda_m1, 
                newdata = test)
pred_qda_train <- predict(qda_m1, 
                newdata = train)

table_qda_test <- table(test$class,pred_qda_test$class)
table_qda_train <- table(train$class,pred_qda_train$class)

error_qda_test <- sum(table_qda_test[row(table_qda_test) != col(table_qda_test)]) / sum(table_qda_test)
error_qda_train <- sum(table_qda_train[row(table_qda_train) != col(table_qda_train)]) / sum(table_qda_train)

#Collect results
results <- as.data.frame(rbind(c(iteration, error_lda_train, error_lda_test, error_qda_train, error_qda_test)))

colnames(results) <- c("iteration", "LDA Training Error", "LDA Test Error", "QDA Training Error", "QDA Test Error")
results
}

##10 obs
final_results_NL_100 <- map_dfr(1:100, run_models_NL_100)

final_results_NL_100 <- final_results_NL_100 %>%
  select(-iteration)
##1000 obs
final_results_NL
##10000 obs
final_results_NL_10000 <- map_dfr(1:10000, run_models_NL_10000)

final_results_NL_10000 <- final_results_NL_10000 %>%
  select(-iteration)
##100000 obs
final_results_NL_100000 <- map_dfr(1:100000, run_models_NL_100000)

final_results_NL_100000 <- final_results_NL_100000 %>%
  select(-iteration)
```

##5 Voter Turnout

###Import and Clean Data
```{r}
#Import data
mental_health <- read_csv("/Users/petecuppernull/Dropbox/UChicago/2019-20/Winter/Computatonal Modeling/Repos/Problem-Set-2/mental_health.csv")

#remove na's
mental_health <- mental_health %>%
  select(vote96, mhealth_sum, age, educ, black, female, married, inc10) %>%
  na.omit() %>%
  mutate(vote96 = as.factor(vote96))

split_mh <- initial_split(mental_health, prop = .7) 
train_mh <- training(split_mh)
test_mh <- testing(split_mh)
```

##Models
```{r}
library(rcfss) # logit2prob function
library(tidymodels) # accuracy function
##Logit
mh_logit <- glm(vote96 ~ ., data = train_mh, family = binomial)
mh_logit_error <- augment(mh_logit, newdata = test_mh) %>% 
  as_tibble() %>%
  mutate(.prob = logit2prob(.fitted),
         .pred = factor(round(.prob))) %>%
  accuracy(truth = vote96, estimate = .pred)

accuracy_logit <- 1 - mh_logit_error$.estimate

##LDA
lda_mh <- MASS::lda(vote96 ~ ., data = train_mh)

mh_lda_test <- predict(lda_mh, 
                newdata = test_mh)
mh_lda_train <- predict(lda_mh, 
                newdata = train_mh)


table_lda_test_mh <- table(test_mh$vote96,mh_lda_test$class)
table_lda_train_mh <- table(train_mh$vote96,mh_lda_train$class)

error_lda_test <- sum(table_lda_test_mh[row(table_lda_test_mh) != col(table_lda_test_mh)]) / sum(table_lda_test_mh)
error_lda_train <- sum(table_lda_train_mh[row(table_lda_train_mh) != col(table_lda_train_mh)]) / sum(table_lda_train_mh)

##QDA
qda_mh <- MASS::qda(vote96 ~ ., data = train_mh)

mh_qda_test <- predict(qda_mh, 
                newdata = test_mh)
mh_qda_train <- predict(qda_mh, 
                newdata = train_mh)


table_qda_test_mh <- table(test_mh$vote96,mh_qda_test$class)
table_qda_train_mh <- table(train_mh$vote96,mh_qda_train$class)

error_qda_test <- sum(table_qda_test_mh[row(table_qda_test_mh) != col(table_qda_test_mh)]) / sum(table_qda_test_mh)
error_qda_train <- sum(table_qda_train_mh[row(table_qda_train_mh) != col(table_qda_train_mh)]) / sum(table_qda_train_mh)

##Naive Bayes -- this isnt working for some reason
# create response and feature data
features <- setdiff(names(train_mh), "Vote") #setdiff(x,y) elements in x but not in y
x <- train_mh[, features]
y <- train_mh$vote96

# set up 10-fold cross validation procedure https://www.rdocumentation.org/packages/caret/versions/6.0-85/topics/trainControl
train_control <- trainControl(
  method = "cv", 
  number = 10
)

# train model
mh_nb <- train(
  x = x,
  y = y,
  method = "nb",
  trControl = train_control
)

pred_mh <- predict(mh_nb, 
                newdata = test_mh)

confusionMatrix(pred_mh, test_mh$vote96)
# results
confusionMatrix(mh_nb)

##KNN
mse_knn_mh <- tibble(k = 1:10,
                  knn_train = map(k, ~ class::knn(select(train_mh, -vote96),
                                                  test = select(train_mh, -vote96),
                                                  cl = train_mh$vote96, k = .)),
                  knn_test = map(k, ~ class::knn(select(train_mh, -vote96),
                                                 test = select(test_mh, -vote96),
                                                 cl = train_mh$vote96, k = .)),
                  err_train = map_dbl(knn_train, ~ mean(test_mh$vote96 != .)),
                  err_test = map_dbl(knn_test, ~ mean(test_mh$vote96 != .)))

ggplot(mse_knn_mh, aes(k, err_test)) +
  geom_line() +
  geom_hline(yintercept = 1 - titanic_logit_error$.estimate[[1]], linetype = 2) +
  labs(x = "K",
       y = "Test error rate") +
  expand_limits(y = 0) + 
  theme_minimal()

```


